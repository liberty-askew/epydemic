#+title: epydemic
#+startup: content

* epydemic: Epidemic simulation in Python                           :PROJECT:

** Release planning

*** Release 1.8.1

**** Coding [0/2]

    - [ ] Add degree-distribution-preserving rewiring functions
      preserving P(k, k') cite:UnreasonableEffectiveness (branch
      rewiring-processes)
    - [ ] Constructing derived generating functions

**** Bugs [0/1]

     - [ ] Import of gf library from pip?


** Sub-projects

*** Acceleration

**** GPU acceleration

 Will need to be [[https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/overview.html][containerised]].

**** Cython acceleration

     Using Cython requires code changes. They're only annotations, to
     provide C types for variables and calling conventions on methods
     -- but fairly substantial changes, and not backwards compatible,
     meaning it'd be a commitment

     Also compare against [[https://github.com/pyston/pyston][Pyston]]

*** PyPy-based compute cluster controlled from CPython [0/2]

    branch pypy-compute

    PyPy doesn't have a full set of library integrations: specifically
    it can't load scipy or matplotlib. That (especially the latter)
    makes it unsuitable for front-end use a lot of the time.

    One way to address this is to run a compute cluster in a PyPy venv
    and control it from Jupyter running in a CPython venv. That way we
    can get the acceleration without the problems.

    Of course this opens up another can of worms. The latest CPython
    is version 3.9; the latest PyPy is on 3.7. So we'd have to run an
    older CPython to avoid language mis-matches.

    - [ ] Set up compute cluster in PyPy linked to Jupyter on CPython
    - [ ] Check interactions between versions

*** Containerisation

    To run in the cloud we need to be able to containerise. There are a
    couple of options here:

    1. A single container running on a multicore host, extended with
       whatever code is needed for the application. This is
       straightforward, but limited by the single-host performance
       (which might be fine for a lot of applications).
    2. Multiple containers acting together, with a virtual network
       between them. This probably needs ~docker-compose~ and some
       tests to see whether it's possible to run ~ipyparallel~ in this
       way (which I think it is).

*** Generating function library [7/8]

    branch gf

    We need a generating functions library, perhaps alongside the
    network generator classes, so we can use this formalism easily
    alongside epydemic's simulations. In particular we need the
    high-order-numerical-derivative function to be able to extract
    probabilities etc. (This turns out to be perfectly possible using
    the factorial functions from mpmath.)

    The biggest challenge might be to write documentation....

    - [X] First version
    - [X] Integrate with calls etc, so they behave like functions
    - [X] Access coefficients by index
    - [X] High-degree (k=1000) coefficient extraction
    - [X] Derivatives
    - [X] Test suite
    - [X] Memoisation
    - [ ] Deriving new generating functions, with more complex
      (functional) values for X

    There's another approach alongside this, which would be to write a
    symbolic package with the generating functions in them, for use in
    Sage. This would then complement the numerical side.

*** Paper on draw set implementation

**** TODO Complete analysis of fairness
     SCHEDULED: <2021-07-07 Wed>
**** TODO Ask Len Thomas about other statistical tests
**** TODO Numerical exploration
**** TODO First draft
